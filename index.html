<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content=“width=800”>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    strongsmall {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
      font-weight: 700
    }

    smalll {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
    }

    stronghuge {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
      font-weight: 700
    }

    huge {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 30px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="sjtu_icon.png">
  <title>Wentao Jiang, Beihang University (BUAA)</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link rel="shortcut icon" href="image/favicon.ico" />
  <link rel="bookmark" href="image/favicon.ico" />
  <meta name="google-site-verification" content="3Pi5gRNVZ_uFXQ1gBBx91DHgGFC32ASIPVvSeEiTqz8" />
  <!-- <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'> -->
  <!-- <link rel="stylesheet" type="text/css" href="stylesheet.css"> -->
</head>

<body>
  <table width="900" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Wentao Jiang &nbsp;&nbsp;<font face="KaiTi" size="6">姜文韬</font>
                </name>
              </p>
              <p>I am currently a first year PhD student at School of Computer Science and Engineering, Beihang
                University (BUAA), supervised by Prof. <a href="http://colalab.org/people">Si Liu</a>. Before that, I was a master student at Beihang
                University (BUAA). I received my B.Eng degree from Harbin Engineering University (HEU) in 2019.
                <p>
                  My research interests include computer vision and deep learning. More specifically, I am interested in
                  generative models and vision & language.
                </p>
                <p align=center>
                  <a href="mailto:jiangwentao@buaa.edu.cn">Email: jiangwentao [at] buaa.edu.cn</a> &nbsp/&nbsp
                  <a href="https://scholar.google.com/citations?hl=en&user=fUKzRuD8RjAC">Google Scholar</a> &nbsp/&nbsp
                  <a href="https://github.com/wtjiang98">Github</a>

                </p>

            </td>
            <td width="20%">
              <img src="images/jwt_2.jpg" width="140">
            </td>
          </tr>
        </table>

        <p></p>
        <p></p>
        <p></p>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>News</heading> &nbsp;
              <p>
                <li> 
                  <em>(2020/03)</em> &nbsp; 1 paper with Prof. Si Liu is accepted
                    by CVPR 2020 as <font color="red">Oral Presentation</font>!<br/>
                  
	  <!-- <li> <strongsmall>[2020/02]</strongsmall> &nbsp;&nbsp;<smalll>1 paper with Prof. Si Liu submitted to ICCV19.</smalll><br/> -->
          <!-- <li> <strongsmall>[2019/02/25]</strongsmall>&nbsp;&nbsp; <smalll>CVPR boardline reject. Better than AAAI. Revise it and try again! </smalll><br/>
          <li> <strongsmall>[2018/12/24]</strongsmall> &nbsp;&nbsp;<smalll>1 revised paper (from AAAI19) submitted to TNNLS. </smalll><br/>
          <li> <strongsmall>[2018/11/13]</strongsmall> &nbsp;&nbsp;<smalll>1 new paper submitted to CVPR19. </smalll><br/>
          <li> <strongsmall>[2018/11/01]</strongsmall> &nbsp;&nbsp;<smalll>My fisrt paper is regected by AAAI19 :(  Keep going! </smalll><br/>
          <li> <strongsmall>[2018/09/08]</strongsmall> &nbsp;&nbsp;<smalll>My fisrt paper submitted to AAAI19.</smalll><br/>  -->
         
              </p>
            </td>
          </tr>
        </table>

        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Education</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="10%">
              <img src='image/uestc_icon.jpg' width="100">
            </td>

            <td width="75%" valign="middle">
              <p>
                <stronghuge>University of Electronic Science and Technology of China (UESTC), China</stronghuge><br />
                Final-year undergraduate in Electronic Information Engineering &nbsp;&nbsp;&nbsp;&nbsp; &bull; Sep. 2016
                - Present <br />
                GPA: <strong>92.98</strong>/100, &nbsp;&nbsp;Ranking: <strong>1/284</strong> (2018-2019) or
                <strong>1/415</strong> (first 2 years)<br />
                Advisors: Prof. <a href="https://interxuxing.github.io/">Xing Xu</a> and Prof. <a
                  href="http://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>. &nbsp;&nbsp; Collaborated with Prof. <a
                  href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/multimedia-computing/people/alan-hanjalic/">Alan
                  Hanjalic</a>
              </p>
            </td>
          </tr>


          <tr>
            <td width="10%">
              <img src='image/chiba_icon.png' width="105">
            </td>

            <td width="90%" valign="middle">
              <p>
                <stronghuge>Chiba University, Japan</stronghuge><br />
                Exchange Program &nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &bull; Aug. 2017 <br />
                <a href="http://www.jst.go.jp/crcc/ssc/">Sakura Science Club Scholarship</a> awardee. Funded by Japan
                Science and Technology Agency <a href="http://www.jst.go.jp/EN/index.html">(JST)</a>.

              </p>
            </td>
          </tr>
        </table> -->

        <p></p>
        <p></p>
        <p></p>
        <p></p>
        <p></p>



        <p></p>
        <p></p>
        <p></p>
        <p></p>
        <p></p>

        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research Experience</heading>
            </td>
          </tr>
        </table> -->

        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="10%">
              <a href="http://cfm.uestc.edu.cn/">
                <img src='image/cfm_icon4.png' width="100">
              </a>
            </td>

            <td width="80%" valign="middle">
              <p>
                <stronghuge>Center For Future Media, UESTC</stronghuge><br />
                <huge><em>Research Assistant</em></huge>&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &bull; Mar. 2018 - Present
                <br />
                Advisors: &nbsp; Prof. <a href="https://interxuxing.github.io/">Xing Xu</a> and Prof. <a
                  href="http://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>. &nbsp;&nbsp;Collaborated with Prof. <a
                  href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/multimedia-computing/people/alan-hanjalic/">Alan
                  Hanjalic</a><br />
                <li> Proposed several novel methods for cross-modal retrieval which achieves the state-of-the-art
                  performance on image-text matching.<br />
                <li> Comnined the GCN with Visual Question Generation Task and further boost the performance on an
                  unexplored challenging task zero-shot VQA. <br />
                <li> Complete 3 works and make the submission.
              </p>
            </td>
          </tr>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="10%">
                <a href="https://mreallab.github.io/people.html">
                  <img src='image/mreal_icon.png' width="100">
                </a>
              </td>

              <td width="80%" valign="middle">
                <p>
                  <stronghuge>MReal Lab, NTU</stronghuge><br />
                  <huge><em>Research Assistant</em></huge>&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &bull; July. 2019 - Present
                  <br />
                  Advisors: &nbsp; Prof. <a href="https://www.ntu.edu.sg/home/hanwangzhang/">Hanwang Zhang </a>
                </p>
              </td>
            </tr> -->



        <p></p>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </table>



        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='images/psgan.jpg' width="200" height="130">
            </td>
            <td valign="top" width="75%">
              <strong>PSGAN: Pose and Expression Robust Spatial-Aware GAN for Customizable Makeup Transfer</strong>
              
              <br><br>
              <strong><u>Wentao Jiang</u></strong>,
              <a href="http://colalab.org/people">Si Liu</a>,
              Chen Gao,
              Jie Cao,
              <a href="http://people.ucas.ac.cn/~0019861?language=en">Ran He</a>,
              <a href="https://sites.google.com/site/jshfeng/">Jiashi Feng</a>,
              <a href="https://www.ece.nus.edu.sg/stfpage/eleyans/">Shuicheng Yan</a>
              <br>
 
              <em>
                IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2020
                <br>
                <em>
                  <strong>
                    <font color="#a82e2e">(Oral Presentation, 5% acceptance rate)</font>
                  </strong></em>
                  <br>
              </em>
                <!-- <br> -->
                <a href="https://arxiv.org/abs/1909.06956"><strong>[Paper]</strong></a>, <a
                  href="https://github.com/wtjiang98/PSGAN"><strong>[Code & Dataset]</strong></a>
                  
                  <br>
            
              <!-- <em>Area: GANs, Fashion</em> -->
              <br>
              <p></p>
              <!-- <p>In this paper, we propose a novel framework for image-text matching that achieves remarkable
                matching performance with acceptable model complexity and much less time consuming.
              </p> -->
            </td>
          </tr>
        </table>




        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='images/ugan.jpg' width="200" height="130">
            </td>
            <td valign="top" width="75%">
              <strong>UGAN: Untraceable GAN for Multi-Domain Face Translation</strong>
              
              <br><br>
              Defa Zhu,
              <a href="http://colalab.org/people">Si Liu</a>,
              <strong><u>Wentao Jiang</u></strong>,
              Chen Gao,
              Tianyi Wu,
              Qaingchang Wang,
              <a href="http://pages.cs.wisc.edu/~gdguo/">Guodong Guo</a>
              <br>
 
              <em>
                arXiv preprint arXiv:1907.11418, 2019
                <br>
              </em>
                <!-- <br> -->
                <a href="https://arxiv.org/abs/1907.11418"><strong>[Paper]</strong></a>
                <!-- , <a
                  href="https://github.com/Wangt-CN/MTFN-RR-PyTorch-Code"><strong>[Code]</strong></a> -->
                  
                  <br>

               <em>
                <!--<strong>
                  <font color="#a82e2e">(Oral Presentation, 4.96% acceptance rate)</font>
                </strong></em> <br> -->

              <!-- <em>Area: GANs</em> -->
              <br>
              <p></p>
              <!-- <p>In this paper, we propose a novel framework for image-text matching that achieves remarkable
                matching performance with acceptable model complexity and much less time consuming.
              </p> -->
            </td>
          </tr>
        </table>


        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='image/CASC1.png' width="200" height="130">
            </td>
            <td valign="top" width="75%">


              <papertitle>Cross-stream Selective Networks for Action Recognition</papertitle>

              <br>


              <a href="https://interxuxing.github.io/">Xing Xu*</a>,
              <strong>Tan Wang*</strong>,
              <a href="http://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>,
              Lin Zuo,
              <a href="http://cfm.uestc.edu.cn/~fshen/">Fumin Shen</a>,
              <a href="http://cfm.uestc.edu.cn/~shenht/">Heng Tao Shen</a> <br>
              <em>IEEE Transactions on Neural Networks and learning systems, <strong>TNNLS 2020</strong> </em> <br>
              <em>Area: Visual and Language, Image-text matching</em> <br>
              <p></p>
              <p>In this paper, we propose a novel hybrid matching approach named Cross-modal Attention with
                Semantic Consistence (CASC) for image-text matching, which is a joint framework that performs
                cross-modal attention for local alignment and multi-label prediction for global semantic
                consistence.</p>
            </td>
          </tr>
        </table> -->




        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='image/radial-gcn.png' width="200" height="130">
            </td>
            <td valign="top" width="75%">
              <strong>Tan Wang</strong>,
              <a href="https://interxuxing.github.io/">Xing Xu</a>,
              <a href="http://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>,
              <a
                href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/multimedia-computing/people/alan-hanjalic/">Alan
                Hanjalic</a>,
              <a href="http://cfm.uestc.edu.cn/~shenht/">Heng Tao Shen</a> <br>
              <em>Under Review</em>, 2019 <br>
              <em>Area: Visual and Language, Visual Question Generation</em> <br>
              <p></p>
              <p>We propose an innovative answer-centric approach
                to focus on the relevant image regions
                only to reduce the complexity on VQG task.</p>
            </td>
          </tr>
        </table> -->

        <p></p>
        <p></p>
        <p></p>
        <p></p>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Honors</heading>
              <div style="line-height:25px">
                <p>
                  <li>
                    Outstanding Freshman Scholarship for PhD Student (Top 5%), Beihang University,&nbsp; 2020<br />
                  <li>
                    First Class Scholarship, Beihang University (Top 10%),&nbsp; 2019<br />
                  <li>
                    Outstanding Freshman Scholarship for Master Student (Top 5%), Beihang University,&nbsp; 2019<br />
                  <!-- <li>
                    Merit Student, Heilongjiang Province (Top 1%),&nbsp;
                    2019<br /> -->
                  <li>
                    Outstanding Graduates, Harbin Engineering University (Top 2%),&nbsp;
                    2019<br />
                  <li>
                    National Scholarship (Top 1%),&nbsp; 2017<br />
                  <li>
                    Silver Medal, ACM-ICPC Asia Regional Contest,&nbsp; 2017<br />
                  <li>
                    Silver Medal &times; 3, China Collegiate Programming Contest (CCPC) Regional Contest,&nbsp;
                    2016-2017<br />

                  <!-- <li>
                    Silver Medal, China Collegiate Programming Contest (CCPC) Regional Contest (Harbin Site),&nbsp;
                    2017<br />

                  <li>
                    Silver Medal, China Collegiate Programming Contest (CCPC) Regional Contest (Hangzhou Site),&nbsp;
                    2016<br /> -->
                  <!-- <li>
                    First Class Scholarship &times; 6, Harbin Engineering University (Top 5%),&nbsp; 2015-2018<br /> -->
                </p>
              </div>
            </td>
          </tr>
        </table>

        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Misc</heading>
              <p>
                I am recruiting a girlfriend now. Please do not hesitate to drop me an email if you are interested.
              </p>
            </td>
          </tr>
        </table> -->

          <p></p>
          <p></p>
          <!-- <script type="text/javascript" id="clustrmaps"
                src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=250&t=tt&d=85Rlf3OqLYVhTE6hGEcHnAsDJl6O0EsUp326ZMpLzCI"></script> -->

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <br>
                  <p align="middle">
                    <font size="2">
                      This template is borrowed from <a href="https://people.eecs.berkeley.edu/~barron/">here</a>.
            </tbody>
          </table>


          <!--  <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-7580334-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
    </td>
    </tr>
  </table>
  <script type="text/javascript" src="//rf.revolvermaps.com/0/0/9.js?i=5m6xs1j09rt&amp;t=bpan" async="async"></script> -->
</body>

</html>