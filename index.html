<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content=“width=800”>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    strongsmall {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
      font-weight: 700
    }

    smalll {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
    }

    stronghuge {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
      font-weight: 700
    }

    huge {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 30px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="sjtu_icon.png">
  <title>Wentao Jiang, Beihang University (BUAA)</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link rel="shortcut icon" href="image/favicon.ico" />
  <link rel="bookmark" href="image/favicon.ico" />
  <meta name="google-site-verification" content="3Pi5gRNVZ_uFXQ1gBBx91DHgGFC32ASIPVvSeEiTqz8" />
  <!-- <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'> -->
  <!-- <link rel="stylesheet" type="text/css" href="stylesheet.css"> -->
</head>

<body>
  <table width="900" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Wentao Jiang &nbsp;&nbsp;<font face="KaiTi" size="6">姜文韬</font>
                </name>
              </p>
              <p> 
		     I am an Algorithm Expert working on image/video generation at Alimama, Alibaba Group, which I joined through the "Alibaba Star Program". I obtained my PhD degree (2019-2024) from the School of Computer Science and Engineering, Beihang
                University (BUAA), supervised by <a href="https://scholar.google.com/citations?user=-QtVtNEAAAAJ">Prof. Si Liu</a>. I used to visit SoC, NUS, supervised by <a href="https://www.comp.nus.edu.sg/~leegh/">Prof. Gim Hee Lee</a>. Before my PhD study, I was a master student at Beihang University (BUAA). I received my B.Eng. degree from Harbin Engineering University (HEU) in 2019.

		      <!--                 <p>
                  <strong><font color="red">我正在积极寻找工业界工作（2024届校招），如果您在招聘且对我感兴趣，十分欢迎您的联系。</font></strong>
                  <br>
                  <font color="red">I am actively looking for a job in industry! Drop me an Email if you are recruiting!</font>
                </p> -->
		      
                <br>
                <p align=center>
                  <a href="mailto:wtjiang98@gmail.com">Email</a> &nbsp/&nbsp
                  <a href="https://scholar.google.com/citations?hl=en&user=fUKzRuD8RjAC">Google Scholar</a> &nbsp/&nbsp
                  <a href="https://github.com/wtjiang98">Github</a> &nbsp/&nbsp
                  <a href="images/WentaoJiang_CV.pdf">CV</a>
                </p>

            </td>
            <td width="20%">
              <img src="images/wb_small.jpg" width="140">
            </td>
          </tr>
        </table>

        

        <p></p>
        <p></p>
        <p></p>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>News</heading> &nbsp;
              <p>
                <!-- <li>
                  <em>(2023/07)</em> <strong><font color="red">&nbsp;&nbsp; 我正在积极寻找工业界工作（24届校招），如果您有招聘需求且对我感兴趣，十分欢迎您的联系。</font></strong>
                </li>
                <li> 
                  <em>(2023/07)</em> &nbsp; <font color="red">I am actively looking for jobs in the industry! Drop me an Email if you are recruiting!</font><br/>
                </li>
                <li></li> -->
                <li> 
                  <em>(2024/07)</em> &nbsp; I join Alibaba Group and work on AIGC area!<br/>
                </li>
		<li> 
                  <em>(2024/06)</em> &nbsp; I receive my PhD degree from Beihang University with my doctoral dissertation "Controlled Image Synthesis and its Application"! <br/>
                </li>
		<li> 
                  <em>(2022/12)</em> &nbsp; I am going to visit the Department of Computer Science at National University of Singapore (NUS)!<br/>
                </li>
                <li>
                  <em>(2022/08)</em> &nbsp; 1 paper with Prof. Si Liu and Dr. Sheng Jin is accepted
                  by ECCV 2022!<br/>
                </li>
                <li> 
                  <em>(2021/07)</em> &nbsp; 1 paper with Prof. Si Liu and Dr. Ning Xu is accepted
                  by ICCV 2021!<br/>
                </li>
                <li> 
                  <em>(2021/05)</em> &nbsp; 1 paper with Prof. Si Liu is accepted
                  by TPAMI 2021!<br/>
                </li>
                <li> 
                  <em>(2020/06)</em> &nbsp; 1 paper with Prof. Si Liu is accepted
                    by CVPR 2020 as <font color="red">Oral Presentation</font>!<br/>
                </li>
	  <!-- <li> <strongsmall>[2020/02]</strongsmall> &nbsp;&nbsp;<smalll>1 paper with Prof. Si Liu submitted to ICCV19.</smalll><br/> -->
          <!-- <li> <strongsmall>[2019/02/25]</strongsmall>&nbsp;&nbsp; <smalll>CVPR boardline reject. Better than AAAI. Revise it and try again! </smalll><br/>
          <li> <strongsmall>[2018/12/24]</strongsmall> &nbsp;&nbsp;<smalll>1 revised paper (from AAAI19) submitted to TNNLS. </smalll><br/>
          <li> <strongsmall>[2018/11/13]</strongsmall> &nbsp;&nbsp;<smalll>1 new paper submitted to CVPR19. </smalll><br/>
          <li> <strongsmall>[2018/11/01]</strongsmall> &nbsp;&nbsp;<smalll>My fisrt paper is regected by AAAI19 :(  Keep going! </smalll><br/>
          <li> <strongsmall>[2018/09/08]</strongsmall> &nbsp;&nbsp;<smalll>My fisrt paper submitted to AAAI19.</smalll><br/>  -->
         
              </p>
            </td>
          </tr>
        </table>

        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Education</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="10%">
              <img src='image/uestc_icon.jpg' width="100">
            </td>

            <td width="75%" valign="middle">
              <p>
                <stronghuge>University of Electronic Science and Technology of China (UESTC), China</stronghuge><br />
                Final-year undergraduate in Electronic Information Engineering &nbsp;&nbsp;&nbsp;&nbsp; &bull; Sep. 2016
                - Present <br />
                GPA: <strong>92.98</strong>/100, &nbsp;&nbsp;Ranking: <strong>1/284</strong> (2018-2019) or
                <strong>1/415</strong> (first 2 years)<br />
                Advisors: Prof. <a href="https://interxuxing.github.io/">Xing Xu</a> and Prof. <a
                  href="http://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>. &nbsp;&nbsp; Collaborated with Prof. <a
                  href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/multimedia-computing/people/alan-hanjalic/">Alan
                  Hanjalic</a>
              </p>
            </td>
          </tr>


          <tr>
            <td width="10%">
              <img src='image/chiba_icon.png' width="105">
            </td>

            <td width="90%" valign="middle">
              <p>
                <stronghuge>Chiba University, Japan</stronghuge><br />
                Exchange Program &nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &bull; Aug. 2017 <br />
                <a href="http://www.jst.go.jp/crcc/ssc/">Sakura Science Club Scholarship</a> awardee. Funded by Japan
                Science and Technology Agency <a href="http://www.jst.go.jp/EN/index.html">(JST)</a>.

              </p>
            </td>
          </tr>
        </table> -->

        <p></p>
        <p></p>
        <p></p>
        <p></p>
        <p></p>



        <p></p>
        <p></p>
        <p></p>
        <p></p>
        <p></p>

        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research Experience</heading>
            </td>
          </tr>
        </table> -->

        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="10%">
              <a href="http://cfm.uestc.edu.cn/">
                <img src='image/cfm_icon4.png' width="100">
              </a>
            </td>

            <td width="80%" valign="middle">
              <p>
                <stronghuge>Center For Future Media, UESTC</stronghuge><br />
                <huge><em>Research Assistant</em></huge>&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &bull; Mar. 2018 - Present
                <br />
                Advisors: &nbsp; Prof. <a href="https://interxuxing.github.io/">Xing Xu</a> and Prof. <a
                  href="http://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>. &nbsp;&nbsp;Collaborated with Prof. <a
                  href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/multimedia-computing/people/alan-hanjalic/">Alan
                  Hanjalic</a><br />
                <li> Proposed several novel methods for cross-modal retrieval which achieves the state-of-the-art
                  performance on image-text matching.<br />
                <li> Comnined the GCN with Visual Question Generation Task and further boost the performance on an
                  unexplored challenging task zero-shot VQA. <br />
                <li> Complete 3 works and make the submission.
              </p>
            </td>
          </tr>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="10%">
                <a href="https://mreallab.github.io/people.html">
                  <img src='image/mreal_icon.png' width="100">
                </a>
              </td>

              <td width="80%" valign="middle">
                <p>
                  <stronghuge>MReal Lab, NTU</stronghuge><br />
                  <huge><em>Research Assistant</em></huge>&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &bull; July. 2019 - Present
                  <br />
                  Advisors: &nbsp; Prof. <a href="https://www.ntu.edu.sg/home/hanwangzhang/">Hanwang Zhang </a>
                </p>
              </td>
            </tr> -->



        <p></p>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Selected Publications</heading>
            </td>
          </tr>
        </table>

	
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='images/augemantation_survey.png' width="200" height="130">
            </td>
            <td valign="top" width="75%">
              <strong>Data Augmentation in Human-Centric Vision</strong>
              
              <br><br>

              <strong><u>Wentao Jiang</u></strong>, Yige Zhang, Shaozhong Zheng, Si Liu, Shuicheng Yan
              <br>
 
              <em>
                Vicinagearth (Springer Nature), 2024
                <br>
                <em>
                  <!-- Minor Revision -->
                  <!-- <strong> -->
                    <!-- <font color="#a82e2e">(Oral Presentation, 5% acceptance rate)</font> -->
                  <!-- </strong> -->
                </em>
                  <!-- <br> -->
              </em>
                <!-- <br> -->
                <!-- <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Jiang_Language-Guided_Global_Image_Editing_via_Cross-Modal_Cyclic_Mechanism_ICCV_2021_paper.pdf"><strong>[Paper]</strong></a> -->
                <!-- <a  href="https://github.com/wtjiang98/PSGAN"><strong>[Code & Dataset]</strong></a> -->
                  <br>
              <!-- <em>Area: GANs, Fashion</em> -->
              <br>
              <p></p>

            </td>
          </tr>
        </table>

	
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='images/iros2024.png' width="200" height="130">
            </td>
            <td valign="top" width="75%">
              <strong>Realistic Rainy Weather Simulation for LiDARs in CARLA Simulator</strong>
              
              <br><br>

              Donglin Yang, Xinyu Cai, Zhenfeng Liu, <strong><u>Wentao Jiang</u></strong>, Bo Zhang, Guohang Yan, Xing Gao, Si Liu, Botian Shi
              <br>
 
              <em>
                International Conference on Intelligent Robots and Systems <strong>(IROS)</strong>, 2024
                <br>
                <em>
                  <!-- Minor Revision -->
                  <!-- <strong> -->
                    <!-- <font color="#a82e2e">(Oral Presentation, 5% acceptance rate)</font> -->
                  <!-- </strong> -->
                </em>
                  <!-- <br> -->
              </em>
                <!-- <br> -->
                <!-- <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Jiang_Language-Guided_Global_Image_Editing_via_Cross-Modal_Cyclic_Mechanism_ICCV_2021_paper.pdf"><strong>[Paper]</strong></a> -->
                <!-- <a  href="https://github.com/wtjiang98/PSGAN"><strong>[Code & Dataset]</strong></a> -->
                  <br>
              <!-- <em>Area: GANs, Fashion</em> -->
              <br>
              <p></p>

            </td>
          </tr>
        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='images/mm23.png' width="200" height="130">
            </td>
            <td valign="top" width="75%">
              <strong>DUSA: Decoupled Unsupervised Sim2Real Adaptation for Vehicle-to-Everything Collaborative Perception</strong>
              
              <br><br>

              Xianghao Kong, <strong><u>Wentao Jiang</u></strong>, Jinrang Jia, Yifeng Shi, Runsheng Xu,
              <a href="http://colalab.org/people">Si Liu</a>
              <br>
 
              <em>
                ACM International Conference on Multimedia <strong>(ACM MM)</strong>, 2023
                <br>
                <em>
                  <!-- Minor Revision -->
                  <!-- <strong> -->
                    <!-- <font color="#a82e2e">(Oral Presentation, 5% acceptance rate)</font> -->
                  <!-- </strong> -->
                </em>
                  <!-- <br> -->
              </em>
                <!-- <br> -->
                <!-- <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Jiang_Language-Guided_Global_Image_Editing_via_Cross-Modal_Cyclic_Mechanism_ICCV_2021_paper.pdf"><strong>[Paper]</strong></a> -->
                <!-- <a  href="https://github.com/wtjiang98/PSGAN"><strong>[Code & Dataset]</strong></a> -->
                  <br>
              <!-- <em>Area: GANs, Fashion</em> -->
              <br>
              <p></p>

            </td>
          </tr>
        </table>

        <!-- \pubItem{Xianghao Kong, \underline{Wentao Jiang}, Jinrang Jia, Yifeng Shi, Runsheng Xu, Si Liu, ``\textbf{DUSA: Decoupled Unsupervised Sim2Real Adaptation for Vehicle-to-Everything Collaborative Perception}'', \textit{ACM International Conference on Multimedia \textbf{(ACM MM)}} 2023 } -->


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='images/rsuopt.png' width="200" height="130">
            </td>
            <td valign="top" width="75%">
              <strong>Optimizing the Placement of Roadside LiDARs for Autonomous Driving</strong>
              
              <br><br>
              <strong><u>Wentao Jiang</u></strong>,
              Hao Xiang, Xinyu Cai, Runsheng Xu, Jiaqi Ma, Yikang Li, Gim Hee Lee, <a href="http://colalab.org/people">Si Liu</a>
              <br>
 
              <em>
                IEEE International Conference on Computer Vision <strong>(ICCV)</strong>, 2023
                <br>
                <em>
                  <!-- Minor Revision -->
                  <!-- <strong> -->
                    <!-- <font color="#a82e2e">(Oral Presentation, 5% acceptance rate)</font> -->
                  <!-- </strong> -->
                </em>
                  <!-- <br> -->
              </em>
                <!-- <br> -->
                <!-- <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Jiang_Language-Guided_Global_Image_Editing_via_Cross-Modal_Cyclic_Mechanism_ICCV_2021_paper.pdf"><strong>[Paper]</strong></a> -->
                <!-- <a  href="https://github.com/wtjiang98/PSGAN"><strong>[Code & Dataset]</strong></a> -->
                  <br>
              <!-- <em>Area: GANs, Fashion</em> -->
              <br>
              <p></p>

            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='images/rsu.png' width="200" height="130">
            </td>
            <td valign="top" width="75%">
              <strong>Analyzing Infrastructure LiDAR Placement with Realistic LiDAR Simulation Library</strong>
              
              <br><br>
              Xinyu Cai*,
              <strong><u>Wentao Jiang*</u></strong>,
              <a href="https://derrickxunu.github.io/">Runsheng Xu</a>,
              Wenquan Zhao,
              Jiaqi Ma,
              <a href="http://colalab.org/people">Si Liu</a>,
              <a href="https://liyikang.top/">Yikang Li</a>
              <br>
              <em>
                IEEE International Conference on Robotics and Automation <strong>(ICRA)</strong>, 2023
                <br>
                <em>
                  <!-- Minor Revision -->
                  <!-- <strong> -->
                    <!-- <font color="#a82e2e">(Oral Presentation, 5% acceptance rate)</font> -->
                  <!-- </strong> -->
                </em>
                  <!-- <br> -->
              </em>
                <!-- <br> -->
                <a href="https://arxiv.org/pdf/2211.15975"><strong>[Paper]</strong></a>
                <a  href="https://github.com/PJLab-ADG/LiDARSimLib-and-Placement-Evaluation"><strong>[Code & Lib]</strong></a>
                  <br>
              <br>
              <p></p>

            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='images/posetrans.png' width="200" height="130">
            </td>
            <td valign="top" width="75%">
              <strong>PoseTrans: A Simple Yet Effective Pose Transformation Augmentation for Human Pose Estimation</strong>
              
              <br><br>
              <strong><u>Wentao Jiang</u></strong>,
              <a href="https://jin-s13.github.io/">Sheng Jin</a>,
              Wentao Liu,
              Chen Qian,
              Ping Luo,
              <a href="http://colalab.org/people">Si Liu</a>
              <br>
 
              <em>
                European Conference on Computer Vision <strong>(ECCV)</strong>, 2022
                <br>
                <em>
                  <!-- Minor Revision -->
                  <!-- <strong> -->
                    <!-- <font color="#a82e2e">(Oral Presentation, 5% acceptance rate)</font> -->
                  <!-- </strong> -->
                </em>
                  <!-- <br> -->
              </em>
                <!-- <br> -->
                <a href="https://arxiv.org/pdf/2208.07755"><strong>[Paper]</strong></a>
                <a  href="https://github.com/wtjiang98/PoseTrans"><strong>[Code]</strong></a>
                  <br>
              <!-- <em>Area: GANs, Fashion</em> -->
              <br>
              <p></p>

            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='images/LGIE.png' width="200" height="130">
            </td>
            <td valign="top" width="75%">
              <strong>Language-Guided Global Image Editing via Cross-Modal Cyclic Mechanism</strong>
              
              <br><br>
              <strong><u>Wentao Jiang</u></strong>,
              Ning Xu,
              Jiayun Wang,
              Chen Gao,
              Jing Shi,
              Zhe Lin,
              <a href="http://colalab.org/people">Si Liu</a>
              <br>
 
              <em>
                IEEE International Conference on Computer Vision <strong>(ICCV)</strong>, 2021
                <br>
                <em>
                  <!-- Minor Revision -->
                  <!-- <strong> -->
                    <!-- <font color="#a82e2e">(Oral Presentation, 5% acceptance rate)</font> -->
                  <!-- </strong> -->
                </em>
                  <!-- <br> -->
              </em>
                <!-- <br> -->
                <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Jiang_Language-Guided_Global_Image_Editing_via_Cross-Modal_Cyclic_Mechanism_ICCV_2021_paper.pdf"><strong>[Paper]</strong></a>
                <!-- <a  href="https://github.com/wtjiang98/PSGAN"><strong>[Code & Dataset]</strong></a> -->
                  <br>
              <!-- <em>Area: GANs, Fashion</em> -->
              <br>
              <p></p>

            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='images/psgan++.png' width="200" height="130">
            </td>
            <td valign="top" width="75%">
              <strong>PSGAN++: Robust Detail-Preserving Makeup Transfer and Removal</strong>
              
              <br><br>
              <a href="http://colalab.org/people">Si Liu</a>,
              <strong><u>Wentao Jiang</u></strong>,
              Chen Gao,
              <a href="http://people.ucas.ac.cn/~0019861?language=en">Ran He</a>,
              <a href="https://sites.google.com/site/jshfeng/">Jiashi Feng</a>,
              Bo Li,
              <a href="https://www.ece.nus.edu.sg/stfpage/eleyans/">Shuicheng Yan</a>
              <br>
 
              <em>
                IEEE Transactions on Pattern Analysis and Machine Intelligence <strong>(TPAMI)</strong>, 2021
                <br>
                <em>
                  <!-- Minor Revision -->
                  <!-- <strong> -->
                    <!-- <font color="#a82e2e">(Oral Presentation, 5% acceptance rate)</font> -->
                  <!-- </strong> -->
                </em>
                  <!-- <br> -->
              </em>
                <!-- <br> -->
                <a href="https://arxiv.org/abs/2105.12324"><strong>[Paper]</strong></a>
                <!-- <a  href="https://github.com/wtjiang98/PSGAN"><strong>[Code & Dataset]</strong></a> -->
                  <br>
              <!-- <em>Area: GANs, Fashion</em> -->
              <br>
              <p></p>
              <!-- <p>In this paper, we propose a novel framework for image-text matching that achieves remarkable
                matching performance with acceptable model complexity and much less time consuming.
              </p> -->
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='images/psgan.jpg' width="200" height="130">
            </td>
            <td valign="top" width="75%">
              <strong>PSGAN: Pose and Expression Robust Spatial-Aware GAN for Customizable Makeup Transfer</strong>
              
              <br><br>
              <strong><u>Wentao Jiang</u></strong>,
              <a href="http://colalab.org/people">Si Liu</a>,
              Chen Gao,
              Jie Cao,
              <a href="http://people.ucas.ac.cn/~0019861?language=en">Ran He</a>,
              <a href="https://sites.google.com/site/jshfeng/">Jiashi Feng</a>,
              <a href="https://www.ece.nus.edu.sg/stfpage/eleyans/">Shuicheng Yan</a>
              <br>
 
              <em>
                IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2020
                <br>
                <em>
                  <strong>
                    <font color="#a82e2e">(Oral Presentation, 5% acceptance rate)</font>
                  </strong></em>
                  <br>
              </em>
                <!-- <br> -->
                <a href="https://arxiv.org/abs/1909.06956"><strong>[Paper]</strong></a>, <a
                  href="https://github.com/wtjiang98/PSGAN"><strong>[Code & Dataset]</strong></a>
                  <br>
              <!-- <em>Area: GANs, Fashion</em> -->
              <br>
              <p></p>
              <!-- <p>In this paper, we propose a novel framework for image-text matching that achieves remarkable
                matching performance with acceptable model complexity and much less time consuming.
              </p> -->
            </td>
          </tr>
        </table>




        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='images/ugan.jpg' width="200" height="130">
            </td>
            <td valign="top" width="75%">
              <strong>UGAN: Untraceable GAN for Multi-Domain Face Translation</strong>
              
              <br><br>
              Defa Zhu,
              <a href="http://colalab.org/people">Si Liu</a>,
              <strong><u>Wentao Jiang</u></strong>,
              Chen Gao,
              Tianyi Wu,
              Qaingchang Wang,
              <a href="http://pages.cs.wisc.edu/~gdguo/">Guodong Guo</a>
              <br>
 
              <em>
                arXiv preprint arXiv:1907.11418, 2019
                <br>
              </em>
                <!-- <br> -->
                <a href="https://arxiv.org/abs/1907.11418"><strong>[Paper]</strong></a>
                <!-- , <a
                  href="https://github.com/Wangt-CN/MTFN-RR-PyTorch-Code"><strong>[Code]</strong></a> -->
                  
                  <br>

               <em>
                <!--<strong>
                  <font color="#a82e2e">(Oral Presentation, 4.96% acceptance rate)</font>
                </strong></em> <br> -->

              <!-- <em>Area: GANs</em> -->
              <br>
              <p></p>
              <!-- <p>In this paper, we propose a novel framework for image-text matching that achieves remarkable
                matching performance with acceptable model complexity and much less time consuming.
              </p> -->
            </td>
          </tr>
        </table>


        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='image/CASC1.png' width="200" height="130">
            </td>
            <td valign="top" width="75%">


              <papertitle>Cross-stream Selective Networks for Action Recognition</papertitle>

              <br>


              <a href="https://interxuxing.github.io/">Xing Xu*</a>,
              <strong>Tan Wang*</strong>,
              <a href="http://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>,
              Lin Zuo,
              <a href="http://cfm.uestc.edu.cn/~fshen/">Fumin Shen</a>,
              <a href="http://cfm.uestc.edu.cn/~shenht/">Heng Tao Shen</a> <br>
              <em>IEEE Transactions on Neural Networks and learning systems, <strong>TNNLS 2020</strong> </em> <br>
              <em>Area: Visual and Language, Image-text matching</em> <br>
              <p></p>
              <p>In this paper, we propose a novel hybrid matching approach named Cross-modal Attention with
                Semantic Consistence (CASC) for image-text matching, which is a joint framework that performs
                cross-modal attention for local alignment and multi-label prediction for global semantic
                consistence.</p>
            </td>
          </tr>
        </table> -->




        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td width="15%">
              <img src='image/radial-gcn.png' width="200" height="130">
            </td>
            <td valign="top" width="75%">
              <strong>Tan Wang</strong>,
              <a href="https://interxuxing.github.io/">Xing Xu</a>,
              <a href="http://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>,
              <a
                href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/multimedia-computing/people/alan-hanjalic/">Alan
                Hanjalic</a>,
              <a href="http://cfm.uestc.edu.cn/~shenht/">Heng Tao Shen</a> <br>
              <em>Under Review</em>, 2019 <br>
              <em>Area: Visual and Language, Visual Question Generation</em> <br>
              <p></p>
              <p>We propose an innovative answer-centric approach
                to focus on the relevant image regions
                only to reduce the complexity on VQG task.</p>
            </td>
          </tr>
        </table> -->

        <p></p>
        <p></p>
        <p></p>
        <p></p>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Honors</heading>
              <div style="line-height:25px">
                <p>
                  <li>
                    National Scholarship (Top 1%),&nbsp; 2021<br />
                  <li>
                    Outstanding Freshman Scholarship for PhD Student (Top 5%), Beihang University,&nbsp; 2020<br />
                  <li>
                    First Class Scholarship, Beihang University (Top 10%),&nbsp; 2019<br />
                  <li>
                    Outstanding Freshman Scholarship for Master Student (Top 5%), Beihang University,&nbsp; 2019<br />
                  <!-- <li>
                    Merit Student, Heilongjiang Province (Top 1%),&nbsp;
                    2019<br /> -->
                  <li>
                    Outstanding Graduates, Harbin Engineering University (Top 2%),&nbsp;
                    2019<br />
                  <li>
                    National Scholarship (Top 1%),&nbsp; 2017<br />
                  <li>
                    Silver Medal, ACM-ICPC Asia Regional Contest,&nbsp; 2017<br />
                  <li>
                    Silver Medal &times; 3, China Collegiate Programming Contest (CCPC) Regional Contest,&nbsp;
                    2016-2017<br />

                  <!-- <li>
                    Silver Medal, China Collegiate Programming Contest (CCPC) Regional Contest (Harbin Site),&nbsp;
                    2017<br />

                  <li>
                    Silver Medal, China Collegiate Programming Contest (CCPC) Regional Contest (Hangzhou Site),&nbsp;
                    2016<br /> -->
                  <!-- <li>
                    First Class Scholarship &times; 6, Harbin Engineering University (Top 5%),&nbsp; 2015-2018<br /> -->
                </p>
              </div>
            </td>
          </tr>
        </table>

        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Misc</heading>
              <p>
                I am recruiting a girlfriend now. Please do not hesitate to drop me an email if you are interested.
              </p>
            </td>
          </tr>
        </table> -->

          <p></p>
          <p></p>
          <!-- <script type="text/javascript" id="clustrmaps"
                src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=250&t=tt&d=85Rlf3OqLYVhTE6hGEcHnAsDJl6O0EsUp326ZMpLzCI"></script> -->

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <br>
                  <p align="middle">
                    <font size="2">
                      ""  <br />
            </tbody>
          </table>


          <!--  <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-7580334-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
    </td>
    </tr>
  </table>
  <script type="text/javascript" src="//rf.revolvermaps.com/0/0/9.js?i=5m6xs1j09rt&amp;t=bpan" async="async"></script> -->
</body>

</html>
